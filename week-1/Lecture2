# 批次梯度下降太慢，每次更新参数前，每一步的梯度下降都要计算损失函数的总和。当数据集很大时，成本高，速度慢。如果数据集小，可以用。
# 大数据集一般采用随机梯度下降，但这种方式不能完全收敛。
# 线性回归没有局部最优。
# 正态方程，只适合线性回归。只需一步，即可达到全局最优。
# 预测值是连续的，是回归；离散的，则为分类。
